import re
from typing import List, Dict

class MedicalSession:
    def __init__(self):
        self.questions_asked = 0
        self.finished = False
        self.last_bot_message = "ØªÙ…Ø§Ù… Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ØŒ ØªÙ‚Ø¯Ø± ØªÙ‚ÙˆÙ„ÙŠ Ø¥ÙŠÙ‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©ØŸ"
        self.useless_responses = {
            "Ù…Ø±Ø­Ø¨Ø§", "Ø§Ù‡Ù„Ø§", "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…", "Ù‡Ø§ÙŠ", "Ø¥Ø²ÙŠÙƒ", 
            "ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±", "Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±", "Ù‡Ù„Ø§", "Ù‡Ø§ÙŠ", "ÙƒÙŠÙÙƒ"
        }
        self.messages = [
            {
                "role": "system",
                "content": "\n".join([
                    "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø·Ø¨ÙŠ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø±Ø¶Ù‰ Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ ÙÙŠ Ø§Ù„ØªØ´Ø®ÙŠØµ.",
                    "Ø³ÙŠØªÙ… ØªØ²ÙˆÙŠØ¯Ùƒ Ø¨Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£ÙˆÙ„ÙŠØ© Ø¹Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø±ÙŠØ¶.",
                    "Ù…Ù‡Ù…ØªÙƒ Ø¥Ù†Ùƒ ØªØ³Ø£Ù„ Ø§Ù„Ù…Ø±ÙŠØ¶ Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙˆØ¯ÙˆØ¯Ø© ÙˆØ·Ø¨ÙŠØ¹ÙŠØ© Ø²ÙŠ Ø¯ÙƒØªÙˆØ± Ø¬Ù„Ø¯ÙŠØ© Ø¨ÙŠØ³Ø£Ù„ Ù…Ø±ÙŠØ¶Ù‡.",
                    "Ù…Ø§ØªØ¨Ø¯Ø§Ø´ Ø¨Ø§Ù„Ø§Ø³Ø§Ù„Ù‡ ØºÙŠØ± Ù„Ù…Ø§ Ø§Ù„Ù…Ø±ÙŠØ¶ ÙŠØ­ÙƒÙŠ Ù…Ø´ÙƒÙ„ØªÙ‡ :Ø§Ø²ÙŠÙƒ Ø¹Ø§Ù…Ù„ Ø§ÙŠÙ‡ Ø§Ùˆ Ø§ÙŠÙ‡ Ø¬Ù…Ù„Ù‡ ØªØ±Ø­ÙŠØ¨ÙŠÙ‡ ,Ø§Ù†Øª Ø§Ù„Ù…ÙØ±ÙˆØ¶ ØªØ±Ø¯ ØªÙ‚ÙˆÙ„Ù‡ ØªÙ…Ø§Ù… Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ ØªÙ‚Ø¯Ø± ØªÙ‚ÙˆÙ„ÙŠ Ù…Ø´ÙƒÙ„ØªÙƒ",
                    "Ø¨Ø¹Ø¯ ÙƒØ¯Ù‡ØŒ Ø§Ø³Ø£Ù„Ù‡ Ø¹Ù† Ø¨Ø¯Ø§ÙŠØ© Ø¸Ù‡ÙˆØ± Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Ù…Ù† Ø¥Ù…ØªÙ‰ Ø¸Ù‡Ø±ØªØŸ",
                    "Ø§Ø³ØªÙØ³Ø± Ø¹Ù† Ø§Ù„ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù„ÙŠ Ø­ØµÙ„Øª Ù„Ù„Ù…ÙƒØ§Ù† Ø¯Ù‡: Ø§Ù„Ù„ÙˆÙ†ØŒ Ø§Ù„Ø­Ø¬Ù…ØŒ Ø§Ù„Ù…Ù„Ù…Ø³ØŒ Ø§Ù„Ù‚Ø´ÙˆØ±ØŒ Ø§Ù„Ø´ÙƒÙ„.",
                    "Ø§Ø³Ø£Ù„Ù‡ Ù„Ùˆ ÙÙŠ Ø£Ø¹Ø±Ø§Ø¶ Ù…ØµØ§Ø­Ø¨Ø©: Ø­ÙƒØ©ØŸ ÙˆØ¬Ø¹ØŸ Ù†Ø²ÙŠÙØŸ Ø£Ùˆ Ø£ÙŠ Ø¥Ø­Ø³Ø§Ø³ ØªØ§Ù†ÙŠ.",
                    "Ø§Ø³Ø£Ù„Ù‡ Ù„Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø£ÙŠ Ø­Ø§Ø¬Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙƒØ§Ù† Ø²ÙŠ Ù…Ø±Ù‡Ù…ØŒ ÙƒØ±ÙŠÙ…ØŒ Ø£Ùˆ ÙˆØµÙØ© Ø¨ÙŠØªÙŠØ©ØŒ ÙˆÙ‡Ù„ Ø­ØµÙ„ ØªØ­Ø³Ù† Ø£Ùˆ Ø³Ø§Ø¡Øª Ø§Ù„Ø­Ø§Ù„Ø©.",
                    "Ø¨Ø¹Ø¯ ÙƒØ¯Ù‡ Ø§Ø³Ø£Ù„Ù‡ Ø¹Ù† Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù„ÙŠ Ù…Ù…ÙƒÙ† ØªÙƒÙˆÙ† Ø¨ØªØ²ÙˆØ¯ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø²ÙŠ: Ù„Ø¨Ø³ Ø¶ÙŠÙ‚ØŒ Ø£Ùˆ Ø§Ù„Ø§Ø­ØªÙƒØ§Ùƒ.",
                    "Ø§Ø³ØªÙØ³Ø± Ø¹Ù† ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ø±Ø¶ Ù„Ù„Ø´Ù…Ø³: Ø´ØºÙ„Ù‡ ÙƒØ§Ù† ÙÙŠÙ‡ Ø´Ù…Ø³ØŸ Ø§ØªØ­Ø±Ù‚ Ù‚Ø¨Ù„ ÙƒØ¯Ù‡ØŸ Ø¨ÙŠØ³ØªØ®Ø¯Ù… ÙˆØ§Ù‚ÙŠ Ø´Ù…Ø³ØŸ",
                    "Ø§Ø³Ø£Ù„Ù‡ Ù„Ùˆ ÙÙŠ ØªØ§Ø±ÙŠØ® Ø¹Ø§Ø¦Ù„ÙŠ Ù„Ø­Ø§Ù„Ø§Øª Ø´Ø¨Ù‡ Ø¯ÙŠØŒ Ø²ÙŠ Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ø¬Ù„Ø¯ Ø£Ùˆ Ø´Ø§Ù…Ø§Øª ØºØ±ÙŠØ¨Ø©.",
                    "Ø§Ø³ØªÙØ³Ø± Ø¹Ù† ÙˆØµÙ Ø´ÙƒÙ„ Ø§Ù„Ø­Ø§Ù„Ù‡ Ø§Ù„ÙŠ Ø¹Ù†Ø¯Ù‡ Ùˆ Ù„Ùˆ Ø¹Ù†Ø¯Ù‡ Ø¹Ù„Ø§Ù…Ø§Øª Ø´Ø¨Ù‡ ØªØ§Ù†ÙŠÙ‡",
                    "ÙŠØ¨Ù‚ÙŠ Ø§Ø³Ø§Ù„Ù‡ Ø³ÙˆØ§Ù„ Ø§Ø®ÙŠØ±  : ÙÙŠ Ø­Ø§Ø¬Ù‡ ØªØ§Ù†ÙŠÙ‡ Ø¹Ø§ÙŠØ² ØªØ¶ÙŠÙÙ‡Ø§ ",
                    "Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø¹Ø§Ù…ÙŠØ© Ù…ØµØ±ÙŠØ© Ø¨Ø³ÙŠØ·Ø© ÙˆÙˆØ§Ø¶Ø­Ø©ØŒ ÙˆØ®Ù„ÙŠÙƒ Ø¯Ø§ÙŠÙ…Ù‹Ø§ Ù…Ù‡ØªÙ… ÙˆØ¨ØªØªÙƒÙ„Ù… Ø¨ÙˆØ¯.",
                    "Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ ÙˆØ§Ø­Ø¯ Ø¨Ø³ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©ØŒ ÙˆÙƒÙ…Ù‘Ù„ Ø¹Ù„Ù‰ Ø­Ø³Ø¨ Ø±Ø¯ Ø§Ù„Ù…Ø±ÙŠØ¶.",
                    "Ù…Ø§ ØªÙ‚Ø¯Ù…Ø´ Ø£ÙŠ ØªØ´Ø®ÙŠØµØŒ Ø´ØºÙ„ØªÙƒ ØªØ¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù„ÙŠ Ø§Ù„Ø¯ÙƒØªÙˆØ± Ù‡ÙŠØ­ØªØ§Ø¬Ù‡Ø§ Ø¨Ø¹Ø¯ ÙƒØ¯Ù‡.",
                    "Ù…Ø§ ØªØ¨Ø¯Ø£Ø´ Ø¨Ù…Ù‚Ø¯Ù…Ø© ÙˆÙ…Ø§ ØªØ®ØªÙ…Ø´ØŒ Ø¨Ø³ ÙƒÙ…Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¹Ù„Ù‰ Ø­Ø³Ø¨ ÙƒÙ„ Ø¥Ø¬Ø§Ø¨Ø©.",
                    "Ø±Ø¯ Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø³"
                ])
            }
        ]

    def process_input(self, user_input: str, tokenizer, model, device: str) -> str:
        user_input_cleaned = user_input.strip().lower()

        if self.finished or re.match(r"^\s*ØªÙ…Ø§Ù…\b", user_input_cleaned, re.IGNORECASE) or user_input_cleaned in ["Ù„Ø§ Ø´ÙƒØ±Ø§", "Ø®Ø±ÙˆØ¬", "Ø§Ù†ØªÙ‡Ø§Ø¡", "exit", "quit"]:
            self.finished = True
            return "Ø´ÙƒØ±Ù‹Ø§ Ù„Ùƒ! Ø£ØªÙ…Ù†Ù‰ Ù„Ùƒ Ø§Ù„ØµØ­Ø© ÙˆØ§Ù„Ø¹Ø§ÙÙŠØ©. ðŸ˜Š"

        self.messages.append({"role": "user", "content": user_input})

        if user_input_cleaned in self.useless_responses:
            response = self.last_bot_message
            self.messages.append({"role": "assistant", "content": response})
            return response

        text = tokenizer.apply_chat_template(self.messages, tokenize=False, add_generation_prompt=True)
        model_inputs = tokenizer([text], return_tensors="pt").to(device)
        generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=100, do_sample=False)

        generated_ids = [
            output_ids[len(input_ids):]
            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
        ]

        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()

        self.last_bot_message = response
        self.messages.append({"role": "assistant", "content": response})
        self.questions_asked += 1

        return response

    def get_full_arabic_conversation(self) -> str:
        return "\n".join([
            f"{'Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯' if msg['role'] == 'assistant' else 'Ø§Ù„Ù…Ø±ÙŠØ¶'}: {msg['content']}"
            for msg in self.messages if msg["role"] in {"user", "assistant"}
        ])
